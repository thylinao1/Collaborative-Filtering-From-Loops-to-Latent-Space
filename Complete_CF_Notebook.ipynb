{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88ba0707",
   "metadata": {},
   "source": [
    "# Collaborative Filtering: From Loops to Latent Space\n",
    "Flow: load the provided data, implement the loop cost function, vectorize it, add my own ratings, normalize, train with TensorFlow, and print recommendations. The cool bit: the model invents its own axes (latent factors) without knowing genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0104ceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from recsys_utils import *  # provided helpers\n",
    "\n",
    "# Load precalculated params and small ratings\n",
    "X, W, b, num_movies, num_features, num_users = load_precalc_params_small()\n",
    "Y, R = load_ratings_small()\n",
    "\n",
    "print('Y', Y.shape, 'R', R.shape)\n",
    "print('X', X.shape, 'W', W.shape, 'b', b.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b04f59",
   "metadata": {},
   "source": [
    "## cost function (loops) + regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dda24ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cofi_cost_func(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"\n",
    "    Returns the cost for the content-based filtering\n",
    "    Args:\n",
    "      X (ndarray (num_movies,num_features)): matrix of item features\n",
    "      W (ndarray (num_users,num_features)) : matrix of user parameters\n",
    "      b (ndarray (1, num_users)            : vector of user parameters\n",
    "      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
    "      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
    "      lambda_ (float): regularization parameter\n",
    "    Returns:\n",
    "      J (float) : Cost\n",
    "    \"\"\"\n",
    "    nm, nu = Y.shape\n",
    "    J = 0\n",
    "    n = W.shape[1]\n",
    "    W1 = np.transpose(W)\n",
    "    for j in range(nu):\n",
    "        w = W[j,:]\n",
    "        b_j = b[0,j]\n",
    "        for i in range(nm):\n",
    "            x = X[i,:]\n",
    "            y = Y[i,j]\n",
    "            r = R[i,j]\n",
    "            J += np.square(r * (np.dot(w,x) + b_j - y ))\n",
    "\n",
    "    J = J/2\n",
    "    lambda_w = 0\n",
    "    for j in range(nu):\n",
    "        for k in range(n):\n",
    "            lambda_w += W[j,k]**2\n",
    "    lambda_x = 0\n",
    "    for j in range(nm):\n",
    "        for k in range(n):\n",
    "            lambda_x += X[j,k]**2\n",
    "\n",
    "    reg = (lambda_*(lambda_w + lambda_x))/2\n",
    "    J = J + reg\n",
    "    return J\n",
    "\n",
    "lambda_ = 1.0\n",
    "J_loop = cofi_cost_func(X, W, b, Y, R, lambda_)\n",
    "print('Cost (loops):', float(J_loop))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942427bd",
   "metadata": {},
   "source": [
    "## Vectorized cost function (NumPy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e808060a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cofi_cost_func_vec(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"Vectorized version of cofi_cost_func.\"\"\"\n",
    "    pred = X @ W.T          # (num_movies Ã— num_users)\n",
    "    pred = pred + b         # b is (1, num_users); broadcasts over rows\n",
    "    err  = (pred - Y) * R\n",
    "    J = 0.5 * np.sum(err * err)\n",
    "    J += 0.5 * lambda_ * (np.sum(W * W) + np.sum(X * X))\n",
    "    return J\n",
    "\n",
    "J_vec = cofi_cost_func_vec(X, W, b, Y, R, lambda_)\n",
    "print('Cost (vectorized):', float(J_vec))\n",
    "print('abs diff:', abs(float(J_vec) - float(J_loop)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5ccab6",
   "metadata": {},
   "source": [
    "## Add my ratings and rebuild matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60229f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "movieList, movieList_df = load_Movie_List_pd()\n",
    "\n",
    "my_ratings = np.zeros(num_movies)\n",
    "# Examples (indices from small_movie_list.csv)\n",
    "my_ratings[2700] = 5  # Toy Story 3 (2010)\n",
    "my_ratings[2609] = 2  # Persuasion (2007)\n",
    "my_ratings[929]  = 5  # LOTR: Return of the King\n",
    "my_ratings[246]  = 5  # Shrek (2001)\n",
    "my_ratings[2716] = 3  # Inception\n",
    "my_ratings[1150] = 5  # The Incredibles (2004)\n",
    "my_ratings[382]  = 2  # Amelie\n",
    "my_ratings[366]  = 5  # Harry Potter 1\n",
    "my_ratings[622]  = 5  # Harry Potter 2\n",
    "my_ratings[988]  = 3  # Eternal Sunshine\n",
    "my_ratings[2925] = 1  # Louis Theroux: Law & Disorder\n",
    "my_ratings[2937] = 1  # Nothing to Declare\n",
    "my_ratings[793]  = 5  # Pirates of the Caribbean 1\n",
    "\n",
    "my_rated = [i for i in range(len(my_ratings)) if my_ratings[i] > 0]\n",
    "\n",
    "print('\\nNew user ratings:\\n')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0:\n",
    "        print(f'Rated {my_ratings[i]} for  {movieList_df.loc[i,\"title\"]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceab4e1",
   "metadata": {},
   "source": [
    "## Reload ratings, append my user, and normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35445d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload ratings\n",
    "Y, R = load_ratings_small()\n",
    "\n",
    "# Add new user as first column\n",
    "Y = np.c_[my_ratings, Y]\n",
    "R = np.c_[(my_ratings != 0).astype(int), R]\n",
    "\n",
    "# Normalize\n",
    "Ynorm, Ymean = normalizeRatings(Y, R)\n",
    "print('Ynorm', Ynorm.shape, 'Ymean', Ymean.shape, 'R', R.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a189b338",
   "metadata": {},
   "source": [
    "## TensorFlow setup and cost (vectorized TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdc4a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_movies, num_users = Y.shape\n",
    "num_features = 100\n",
    "\n",
    "tf.random.set_seed(1234)\n",
    "W = tf.Variable(tf.random.normal((num_users,  num_features), dtype=tf.float64), name='W')\n",
    "X = tf.Variable(tf.random.normal((num_movies, num_features), dtype=tf.float64), name='X')\n",
    "b = tf.Variable(tf.random.normal((1,          num_users),    dtype=tf.float64), name='b')\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-1)\n",
    "\n",
    "def cofi_cost_func_v(X, W, b, Y, R, lambda_):\n",
    "    pred = tf.matmul(X, W, transpose_b=True) + b  # (m,u)\n",
    "    err  = (pred - tf.constant(Y, dtype=tf.float64)) * tf.constant(R, dtype=tf.float64)\n",
    "    J    = 0.5 * tf.reduce_sum(tf.square(err))\n",
    "    J   += 0.5 * lambda_ * (tf.reduce_sum(tf.square(X)) +\n",
    "                            tf.reduce_sum(tf.square(W)) +\n",
    "                            tf.reduce_sum(tf.square(b)))\n",
    "    return J\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0510fdfa",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4148b701",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 200\n",
    "lambda_ = 1.0\n",
    "\n",
    "for iter in range(iterations):\n",
    "    with tf.GradientTape() as tape:\n",
    "        cost_value = cofi_cost_func_v(X, W, b, Ynorm, R, lambda_)\n",
    "    grads = tape.gradient(cost_value, [X, W, b])\n",
    "    optimizer.apply_gradients(zip(grads, [X, W, b]))\n",
    "    if iter % 20 == 0:\n",
    "        print(f'Training loss at iteration {iter}: {cost_value:0.1f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67614fd",
   "metadata": {},
   "source": [
    "## Predict and print recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2ba50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p  = np.matmul(X.numpy(), np.transpose(W.numpy())) + b.numpy()\n",
    "pm = p + Ymean\n",
    "my_predictions = pm[:, 0]\n",
    "ix = tf.argsort(my_predictions, direction='DESCENDING')\n",
    "\n",
    "print('\\nTop recommendations (unrated by me):')\n",
    "shown = 0\n",
    "for i in range(len(my_predictions)):\n",
    "    j = int(ix[i])\n",
    "    if j not in my_rated:\n",
    "        print(f'Predicting rating {my_predictions[j]:0.2f} for movie {movieList[j]}')\n",
    "        shown += 1\n",
    "    if shown == 17:\n",
    "        break\n",
    "\n",
    "print('\\n\\nOriginal vs Predicted ratings:\\n')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0:\n",
    "        print(f'Original {my_ratings[i]}, Predicted {my_predictions[i]:0.2f} for {movieList[i]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
