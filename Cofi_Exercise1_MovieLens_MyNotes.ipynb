{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63dabd05",
   "metadata": {},
   "source": [
    "\n",
    "# Collaborative Filtering — my Exercise 1 notes (MovieLens small)\n",
    "\n",
    "I'm coding this the way I do it myself: load the provided data, implement the cost function with loops (with regularization), \n",
    "check it, then do the same thing vectorized and compare. Keeping it close to the assignment flow and names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e4b60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from recsys_utils import *  # provided with the assignment\n",
    "\n",
    "# Load precomputed parameters and ratings (small set)\n",
    "X, W, b, num_movies, num_features, num_users = load_precalc_params_small()\n",
    "Y, R = load_ratings_small()\n",
    "\n",
    "print(\"Y\", Y.shape, \"R\", R.shape)\n",
    "print(\"X\", X.shape, \"W\", W.shape, \"b\", b.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3945a39",
   "metadata": {},
   "source": [
    "\n",
    "## Exercise 1 — cost function (loops) + regularization\n",
    "\n",
    "This is the straightforward loop version. I’m only counting entries where `R[i,j] == 1`. \n",
    "Regularization is added on `X` and `W` to match the assignment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f56a92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cofi_cost_func(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"\n",
    "    Returns the cost for the content-based filtering\n",
    "    Args:\n",
    "      X (ndarray (num_movies,num_features)): matrix of item features\n",
    "      W (ndarray (num_users,num_features)) : matrix of user parameters\n",
    "      b (ndarray (1, num_users)            : vector of user parameters\n",
    "      Y (ndarray (num_movies,num_users)    : matrix of user ratings of movies\n",
    "      R (ndarray (num_movies,num_users)    : matrix, where R(i, j) = 1 if the i-th movies was rated by the j-th user\n",
    "      lambda_ (float): regularization parameter\n",
    "    Returns:\n",
    "      J (float) : Cost\n",
    "    \"\"\"\n",
    "    nm, nu = Y.shape\n",
    "    J = 0\n",
    "    n = W.shape[1]\n",
    "    ### START CODE HERE ### \n",
    "    W1 = np.transpose(W)\n",
    "    for j in range(nu):\n",
    "        w = W[j,:]\n",
    "        b_j = b[0,j]\n",
    "        for i in range(nm):\n",
    "            x = X[i,:]\n",
    "            y = Y[i,j]\n",
    "            r = R[i,j]\n",
    "            J += np.square(r * (np.dot(w,x) + b_j - y )) \n",
    "            \n",
    "    \n",
    "    J = J/2\n",
    "    lambda_w = 0\n",
    "    for j in range(nu):\n",
    "        for k in range(n):\n",
    "            lambda_w += W[j,k]**2\n",
    "    lambda_x = 0\n",
    "    for j in range(nm):\n",
    "        for k in range(n):\n",
    "            lambda_x += X[j,k]**2\n",
    "            \n",
    "    reg = (lambda_*(lambda_w + lambda_x))/2\n",
    "    J = J + reg\n",
    "    ### END CODE HERE ### \n",
    "\n",
    "    return J\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef545e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lambda_ = 1.0\n",
    "J_loop = cofi_cost_func(X, W, b, Y, R, lambda_)\n",
    "print(\"Cost (loops):\", float(J_loop))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6f4e92",
   "metadata": {},
   "source": [
    "\n",
    "## Vectorized cost function (same result, no loops)\n",
    "\n",
    "Same signature and behavior; computes the same cost using matrix ops.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d645f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cofi_cost_func_vec(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"Vectorized version of cofi_cost_func.\"\"\"\n",
    "    pred = X @ W.T          # (num_movies × num_users)\n",
    "    pred = pred + b         # b is (1, num_users); broadcasts over rows\n",
    "    err  = (pred - Y) * R\n",
    "    J = 0.5 * np.sum(err * err)\n",
    "    J += 0.5 * lambda_ * (np.sum(W * W) + np.sum(X * X))\n",
    "    return J\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29cc7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "J_vec = cofi_cost_func_vec(X, W, b, Y, R, lambda_)\n",
    "print(\"Cost (vectorized):\", float(J_vec))\n",
    "print(\"abs diff:\", abs(float(J_vec) - float(J_loop)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75894d5",
   "metadata": {},
   "source": [
    "\n",
    "## Why this is cool (my take)\n",
    "\n",
    "The model doesn’t know genres, tags, or any hand-crafted features. It doesn’t even know which “axes” matter. \n",
    "When we learn `X` (movie features) and `W` (user preferences), we’re letting the model **invent the axes** that best explain the ratings.  \n",
    "Each dimension ends up capturing some latent factor that influences taste. We never label those factors; the training creates them implicitly.  \n",
    "That’s why the same basic implementation can adapt to many domains beyond movies — whenever you have entities, users, and sparse feedback, \n",
    "these learned axes will reorganize themselves to fit the data.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
